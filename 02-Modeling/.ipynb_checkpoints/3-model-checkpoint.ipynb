{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Rd. 3\n",
    "---\n",
    "This round I am using the subsets of the original data set that yielded the best results from the previous step of modeling. Specifically, the Logistic Regression performed on the 'heavy class' subset, as well as, the Logistic Regression performed on the 'upper class' subset. These two datasets will be imported and run through ridge regularization to reduce the overfitting that is exhibited in the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Text Processing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Machine Learning packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Model training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier, RidgeClassifierCV\n",
    "#from sklearn.linear_model import LassoClassifier, LassoClassifierCV\n",
    "\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>no. of. words</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp  intj moments   sportscenter    plays...</td>\n",
       "      <td>344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good         course  which    know thats  bles...</td>\n",
       "      <td>215</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp    enjoyed  conversation  other    e...</td>\n",
       "      <td>611</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>science    perfect   scientist claims tha...</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>cant draw    nails haha  those were done  pr...</td>\n",
       "      <td>775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  no. of. words  \\\n",
       "0  INFJ      enfp  intj moments   sportscenter    plays...            344   \n",
       "1  INTP  good         course  which    know thats  bles...            215   \n",
       "2  INTJ  dear intp    enjoyed  conversation  other    e...            611   \n",
       "3  INTJ       science    perfect   scientist claims tha...            189   \n",
       "4  INFJ    cant draw    nails haha  those were done  pr...            775   \n",
       "\n",
       "   class  \n",
       "0      0  \n",
       "1      3  \n",
       "2      2  \n",
       "3      2  \n",
       "4      0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/heavy_sample.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>no. of. words</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding  lack    these posts very alarming   ...</td>\n",
       "      <td>639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>doesnt want     trip without    staying behin...</td>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>they paint without numbers    guess  istp     ...</td>\n",
       "      <td>492</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>enfps   posted this thread   philosophy board...</td>\n",
       "      <td>820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISTP</td>\n",
       "      <td>from what  read about  enneagram    thoug...</td>\n",
       "      <td>849</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  no. of. words  \\\n",
       "0  ENTP   finding  lack    these posts very alarming   ...            639   \n",
       "1  ENFP   doesnt want     trip without    staying behin...            305   \n",
       "2  ISFP  they paint without numbers    guess  istp     ...            492   \n",
       "3  ENFP   enfps   posted this thread   philosophy board...            820   \n",
       "4  ISTP       from what  read about  enneagram    thoug...            849   \n",
       "\n",
       "   class  \n",
       "0      1  \n",
       "1      0  \n",
       "2      2  \n",
       "3      0  \n",
       "4      3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_df = pd.read_csv('../data/upper_sample.csv')\n",
    "upper_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Logistic regression\n",
    "---\n",
    "### Heavy Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing posts for model by vectorzing and filtering stop-words\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english')\n",
    "\n",
    "X = cvec.fit_transform(df['posts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file in the current working directory\n",
    "pkl_filename = \"../data/pickle_vectorizer.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(cvec, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining y (target feature)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4460, 79517) (4460,) (1115, 79517) (1115,)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print ((X_train.shape),(y_train.shape),(X_test.shape),(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.70       287\n",
      "           1       0.72      0.78      0.75       356\n",
      "           2       0.72      0.65      0.68       215\n",
      "           3       0.70      0.70      0.70       257\n",
      "\n",
      "    accuracy                           0.71      1115\n",
      "   macro avg       0.71      0.71      0.71      1115\n",
      "weighted avg       0.71      0.71      0.71      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = logreg.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "report = classification_report(y_test, preds)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_train = logreg.score(X_train, y_train)\n",
    "\n",
    "logreg_test = logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.862780269058296\n",
      "Testing Accuracy:  0.7139013452914799\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy:  {logreg_train}')\n",
    "print(f'Testing Accuracy:  {logreg_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115, 79517)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Logistic Regression\n",
    "---\n",
    "### Upper Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing posts for model by vectorzing and filtering stop-words\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english')\n",
    "\n",
    "X = cvec.fit_transform(upper_df['posts'])\n",
    "\n",
    "# Defining y (target feature)\n",
    "y = upper_df['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1515, 40908) (1515,) (379, 40908) (379,)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print ((X_train.shape),(y_train.shape),(X_test.shape),(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80       127\n",
      "           1       0.82      0.80      0.81       133\n",
      "           2       0.74      0.55      0.63        53\n",
      "           3       0.80      0.68      0.74        66\n",
      "\n",
      "    accuracy                           0.78       379\n",
      "   macro avg       0.78      0.73      0.75       379\n",
      "weighted avg       0.78      0.78      0.77       379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = logreg.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "report = classification_report(y_test, preds)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_train = logreg.score(X_train, y_train)\n",
    "\n",
    "logreg_test = logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  0.7757255936675461\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy:  {logreg_train}')\n",
    "print(f'Testing Accuracy:  {logreg_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regularization\n",
    "---\n",
    "### Heavy Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing posts for model by vectorzing and filtering stop-words\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english')\n",
    "\n",
    "X = cvec.fit_transform(df['posts'])\n",
    "\n",
    "# Defining y (target feature)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print ((X_train.shape),(y_train.shape),(X_test.shape),(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.64      0.70       287\n",
      "           1       0.65      0.87      0.74       356\n",
      "           2       0.78      0.59      0.67       215\n",
      "           3       0.74      0.68      0.71       257\n",
      "\n",
      "    accuracy                           0.71      1115\n",
      "   macro avg       0.74      0.69      0.71      1115\n",
      "weighted avg       0.73      0.71      0.71      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate.\n",
    "\n",
    "ridge_model = RidgeClassifier(900) #played around with alpha manually for a bit to gauge where it wanted to settle at\n",
    "\n",
    "# Fit.\n",
    "\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = ridge_model.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "report = classification_report(y_test, preds)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_train = ridge_model.score(X_train, y_train)\n",
    "ridge_test = ridge_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8798206278026905\n",
      "Testing Accuracy:  0.7130044843049327\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy:  {ridge_train}')\n",
    "print(f'Testing Accuracy:  {ridge_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeClassifierCV\n",
    "---\n",
    "Finds best value of alpha and runs the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 2min 43s, sys: 6min 35s, total: 1h 9min 19s\n",
      "Wall time: 43min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RidgeClassifierCV(alphas=array([1.00000000e+00, 1.12332403e+00, 1.26185688e+00, 1.41747416e+00,\n",
       "       1.59228279e+00, 1.78864953e+00, 2.00923300e+00, 2.25701972e+00,\n",
       "       2.53536449e+00, 2.84803587e+00, 3.19926714e+00, 3.59381366e+00,\n",
       "       4.03701726e+00, 4.53487851e+00, 5.09413801e+00, 5.72236766e+00,\n",
       "       6.42807312e+00, 7.22080902e+00, 8.11130831e+00, 9.11162756e+00,\n",
       "       1.02353102e+01, 1.1...\n",
       "       6.89261210e+03, 7.74263683e+03, 8.69749003e+03, 9.77009957e+03,\n",
       "       1.09749877e+04, 1.23284674e+04, 1.38488637e+04, 1.55567614e+04,\n",
       "       1.74752840e+04, 1.96304065e+04, 2.20513074e+04, 2.47707636e+04,\n",
       "       2.78255940e+04, 3.12571585e+04, 3.51119173e+04, 3.94420606e+04,\n",
       "       4.43062146e+04, 4.97702356e+04, 5.59081018e+04, 6.28029144e+04,\n",
       "       7.05480231e+04, 7.92482898e+04, 8.90215085e+04, 1.00000000e+05]),\n",
       "                  cv=5, scoring='r2')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Set up a list of ridge alphas to check.\n",
    "# np.logspace generates 100 values equally between 0 and 5,\n",
    "# then converts them to alphas between 10^0 and 10^5.\n",
    "\n",
    "r_alphas = np.logspace(0,5,100)\n",
    "\n",
    "# Cross-validate over our list of ridge alphas.\n",
    "\n",
    "ridge_cv = RidgeClassifierCV(alphas=r_alphas, scoring ='r2', cv=5)\n",
    "\n",
    "# Fit model using best ridge alpha!\n",
    "\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2154.4346900318847"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the optimal value of alpha\n",
    "\n",
    "ridge_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8271300448430493\n",
      "0.7165919282511211\n"
     ]
    }
   ],
   "source": [
    "print(ridge_cv.score(X_train, y_train))\n",
    "print(ridge_cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving best model to deploy on streamlit app\n",
    "\n",
    "pkl_filename = \"../data/pickle_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(ridge_cv, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure I can reload model\n",
    "\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    pickle_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8271300448430493\n",
      "0.7165919282511211\n"
     ]
    }
   ],
   "source": [
    "# Ensuring model yields same results\n",
    "\n",
    "print(pickle_model.score(X_train, y_train))\n",
    "print(pickle_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regularization\n",
    "---\n",
    "### Upper Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing posts for model by vectorzing and filtering stop-words\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english')\n",
    "\n",
    "X = cvec.fit_transform(upper_df['posts'])\n",
    "\n",
    "# Defining y (target feature)\n",
    "y = upper_df['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1515, 40908) (1515,) (379, 40908) (379,)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print ((X_train.shape),(y_train.shape),(X_test.shape),(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.90      0.75       127\n",
      "           1       0.80      0.80      0.80       133\n",
      "           2       0.85      0.42      0.56        53\n",
      "           3       0.89      0.59      0.71        66\n",
      "\n",
      "    accuracy                           0.74       379\n",
      "   macro avg       0.79      0.68      0.70       379\n",
      "weighted avg       0.77      0.74      0.73       379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate.\n",
    "\n",
    "ridge_model = RidgeClassifier(900)\n",
    "\n",
    "# Fit.\n",
    "\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = ridge_model.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "report = classification_report(y_test, preds)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_train = ridge_model.score(X_train, y_train)\n",
    "ridge_test = ridge_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.899009900990099\n",
      "Testing Accuracy:  0.741424802110818\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy:  {ridge_train}')\n",
    "print(f'Testing Accuracy:  {ridge_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeClassifierCV\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 9s, sys: 53.7 s, total: 9min 3s\n",
      "Wall time: 6min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RidgeClassifierCV(alphas=array([1.00000000e+00, 1.12332403e+00, 1.26185688e+00, 1.41747416e+00,\n",
       "       1.59228279e+00, 1.78864953e+00, 2.00923300e+00, 2.25701972e+00,\n",
       "       2.53536449e+00, 2.84803587e+00, 3.19926714e+00, 3.59381366e+00,\n",
       "       4.03701726e+00, 4.53487851e+00, 5.09413801e+00, 5.72236766e+00,\n",
       "       6.42807312e+00, 7.22080902e+00, 8.11130831e+00, 9.11162756e+00,\n",
       "       1.02353102e+01, 1.1...\n",
       "       6.89261210e+03, 7.74263683e+03, 8.69749003e+03, 9.77009957e+03,\n",
       "       1.09749877e+04, 1.23284674e+04, 1.38488637e+04, 1.55567614e+04,\n",
       "       1.74752840e+04, 1.96304065e+04, 2.20513074e+04, 2.47707636e+04,\n",
       "       2.78255940e+04, 3.12571585e+04, 3.51119173e+04, 3.94420606e+04,\n",
       "       4.43062146e+04, 4.97702356e+04, 5.59081018e+04, 6.28029144e+04,\n",
       "       7.05480231e+04, 7.92482898e+04, 8.90215085e+04, 1.00000000e+05]),\n",
       "                  cv=5, scoring='r2')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Set up a list of ridge alphas to check.\n",
    "# np.logspace generates 100 values equally between 0 and 5,\n",
    "# then converts them to alphas between 10^0 and 10^5.\n",
    "\n",
    "r_alphas = np.logspace(0,5,100)\n",
    "\n",
    "# Cross-validate over our list of ridge alphas.\n",
    "\n",
    "ridge_cv = RidgeClassifierCV(alphas=r_alphas, scoring ='r2', cv=5)\n",
    "\n",
    "# Fit model using best ridge alpha!\n",
    "\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599.4842503189409"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the optimal value of alpha\n",
    "\n",
    "ridge_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9174917491749175\n",
      "0.7440633245382586\n"
     ]
    }
   ],
   "source": [
    "print(ridge_cv.score(X_train, y_train))\n",
    "print(ridge_cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
