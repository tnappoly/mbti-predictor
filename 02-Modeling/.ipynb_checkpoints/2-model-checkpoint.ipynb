{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Rd. 2\n",
    "---\n",
    "This round I wanted to subset my data into four distinct categories ordered by number of posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Text Processing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Machine Learning packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Model training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>no. of. words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp  intj moments   sportscenter    plays...</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding  lack    these posts very alarming   ...</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good         course  which    know thats  bles...</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp    enjoyed  conversation  other    e...</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>youre fired    thats another silly misconcepti...</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  no. of. words\n",
       "0  INFJ      enfp  intj moments   sportscenter    plays...            344\n",
       "1  ENTP   finding  lack    these posts very alarming   ...            639\n",
       "2  INTP  good         course  which    know thats  bles...            215\n",
       "3  INTJ  dear intp    enjoyed  conversation  other    e...            611\n",
       "4  ENTJ  youre fired    thats another silly misconcepti...            315"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/clean_mbti_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFP    0.209578\n",
       "INFJ    0.169867\n",
       "INTP    0.151849\n",
       "INTJ    0.127193\n",
       "ENTP    0.078947\n",
       "ENFP    0.075273\n",
       "ISTP    0.038762\n",
       "ISFP    0.031532\n",
       "ENTJ    0.026671\n",
       "ISTJ    0.023945\n",
       "ENFJ    0.021219\n",
       "ISFJ    0.019440\n",
       "ESTP    0.010550\n",
       "ESFP    0.005571\n",
       "ESFJ    0.004979\n",
       "ESTJ    0.004623\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, nearly half of our data is represented in the top four classes starting with the most prevalent class, 'INFP'. I plan to run a another round of modeling splitting the types category into groups of four in descending order of number of posts. I will split the categories into a heavy class, upper class, lower class, and finally a light class to extract more insight from this dataset.\n",
    "\n",
    "As I said before, I chose not to impute these values to have balanced classes so this will serve as a work around."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heavy Class Modeling\n",
    "---\n",
    "Heavy Class will include the top four categories with most the data ('INFP', 'INFJ', 'INTP', 'INTJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this bit of code to prevent long error messages, but be mindful that you may not see a message worth looking into when debugging code\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INFJ' 'INTP' 'INTJ' 'INFP']\n",
      "(5555, 3)\n"
     ]
    }
   ],
   "source": [
    "# Subsetting the heavy class\n",
    "\n",
    "heavy_class = ['INFP','INFJ','INTP', 'INTJ']\n",
    "\n",
    "heavy_sample = df[df['type'].isin(heavy_class)]\n",
    "\n",
    "print(heavy_sample.type.unique())\n",
    "\n",
    "print(heavy_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizing MBTI personality types(target feature) using LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "heavy_sample['class'] = encoder.fit_transform(heavy_sample['type'])\n",
    "\n",
    "# Defining y (target feature)\n",
    "y = heavy_sample['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>no. of. words</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp  intj moments   sportscenter    plays...</td>\n",
       "      <td>344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good         course  which    know thats  bles...</td>\n",
       "      <td>215</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp    enjoyed  conversation  other    e...</td>\n",
       "      <td>611</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>science    perfect   scientist claims tha...</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>cant draw    nails haha  those were done  pr...</td>\n",
       "      <td>775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  no. of. words  \\\n",
       "0  INFJ      enfp  intj moments   sportscenter    plays...            344   \n",
       "2  INTP  good         course  which    know thats  bles...            215   \n",
       "3  INTJ  dear intp    enjoyed  conversation  other    e...            611   \n",
       "5  INTJ       science    perfect   scientist claims tha...            189   \n",
       "6  INFJ    cant draw    nails haha  those were done  pr...            775   \n",
       "\n",
       "   class  \n",
       "0      0  \n",
       "2      3  \n",
       "3      2  \n",
       "5      2  \n",
       "6      0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure that label encoding successully binarized type column\n",
    "\n",
    "heavy_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(heavy_sample['class'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now there are 4 target features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFP    0.318924\n",
       "INFJ    0.257758\n",
       "INTP    0.230493\n",
       "INTJ    0.192825\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heavy_sample['type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-vectorized shape\n",
    "pre_vect = heavy_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing posts for model by vectorzing and filtering stop-words\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english')\n",
    "\n",
    "X = cvec.fit_transform(heavy_sample['posts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5575, 79517)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# post-vectorized shape\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4460, 79517) (4460,) (1115, 79517) (1115,)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print ((X_train.shape),(y_train.shape),(X_test.shape),(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.70       287\n",
      "           1       0.72      0.78      0.75       356\n",
      "           2       0.72      0.65      0.68       215\n",
      "           3       0.70      0.70      0.70       257\n",
      "\n",
      "    accuracy                           0.71      1115\n",
      "   macro avg       0.71      0.71      0.71      1115\n",
      "weighted avg       0.71      0.71      0.71      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = logreg.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "report = classification_report(y_test, preds)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_train = logreg.score(X_train, y_train)\n",
    "\n",
    "logreg_test = logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.862780269058296\n",
      "Testing Accuracy:  0.7139013452914799\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy:  {logreg_train}')\n",
    "print(f'Testing Accuracy:  {logreg_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.55      0.59       287\n",
      "           1       0.57      0.86      0.69       356\n",
      "           2       0.74      0.33      0.45       215\n",
      "           3       0.66      0.60      0.63       257\n",
      "\n",
      "    accuracy                           0.62      1115\n",
      "   macro avg       0.65      0.59      0.59      1115\n",
      "weighted avg       0.64      0.62      0.60      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Fit the model on the training data\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = nb.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "report = classification_report(y_test, preds)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = nb.score(X_train, y_train)\n",
    "nb_test = nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9394618834080718\n",
      "Testing Accuracy:  0.6188340807174888\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy:  {nb_train}')\n",
    "print(f'Testing Accuracy:  {nb_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.47      0.38       287\n",
      "           1       0.43      0.50      0.46       356\n",
      "           2       0.31      0.18      0.22       215\n",
      "           3       0.37      0.24      0.29       257\n",
      "\n",
      "    accuracy                           0.37      1115\n",
      "   macro avg       0.36      0.35      0.34      1115\n",
      "weighted avg       0.37      0.37      0.36      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Fit the model on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = knn.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "report = classification_report(y_test, preds)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train = knn.score(X_train, y_train)\n",
    "knn_test = knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.5728699551569507\n",
      "Testing Accuracy:  0.368609865470852\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy:  {knn_train}')\n",
    "print(f'Testing Accuracy:  {knn_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.46      0.54       287\n",
      "           1       0.49      0.90      0.64       356\n",
      "           2       0.79      0.36      0.50       215\n",
      "           3       0.70      0.45      0.55       257\n",
      "\n",
      "    accuracy                           0.58      1115\n",
      "   macro avg       0.66      0.54      0.56      1115\n",
      "weighted avg       0.64      0.58      0.56      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "report = classification_report(y_test, preds)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train = rf.score(X_train, y_train)\n",
    "rf_test = rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  0.579372197309417\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy:  {rf_train}')\n",
    "print(f'Testing Accuracy:  {rf_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving heavy sample for next model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "heavy_sample.to_csv('../data/heavy_sample.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium Class Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTP     685\n",
    "ENFP     675\n",
    "ISTP     337\n",
    "ISFP     271"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_class = ['ENTP','ENFP','ISTP','ISFP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_sample = df[df['type'].isin(medium_class)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ENTP', 'ENFP', 'ISFP', 'ISTP'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_sample.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1901, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENTP    0.350868\n",
       "ENFP    0.336139\n",
       "ISTP    0.172541\n",
       "ISFP    0.140452\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_sample['type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tnappoly/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Binarizing MBTI personality types(target feature) using LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "medium_sample['class'] = encoder.fit_transform(medium_sample['type'])\n",
    "\n",
    "# Defining y (target feature)\n",
    "y = medium_sample['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Making sure that label encoding successully binarized type column\n",
    "\n",
    "print(len(heavy_sample['class'].unique()))\n",
    "print(len(heavy_sample['class'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>no. of. words</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>finding  lack    these posts very alarming eo...</td>\n",
       "      <td>803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>doesnt want     trip without    staying behin...</td>\n",
       "      <td>389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>they paint without numbers    guess  istp     ...</td>\n",
       "      <td>607</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>enfps eostokendot   posted this thread   phil...</td>\n",
       "      <td>1063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ISTP</td>\n",
       "      <td>eostokendot   from what  read about  enneag...</td>\n",
       "      <td>1070</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                                              posts  no. of. words  \\\n",
       "1   ENTP   finding  lack    these posts very alarming eo...            803   \n",
       "25  ENFP   doesnt want     trip without    staying behin...            389   \n",
       "26  ISFP  they paint without numbers    guess  istp     ...            607   \n",
       "37  ENFP   enfps eostokendot   posted this thread   phil...           1063   \n",
       "39  ISTP     eostokendot   from what  read about  enneag...           1070   \n",
       "\n",
       "    class  \n",
       "1       1  \n",
       "25      0  \n",
       "26      2  \n",
       "37      0  \n",
       "39      3  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing posts for model by vectorzing and filtering stop-words\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english')\n",
    "\n",
    "X = cvec.fit_transform(medium_sample['posts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1901, 40911)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# post-vectorized shape\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1520, 40911) (1520,) (381, 40911) (381,)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print ((X_train.shape),(y_train.shape),(X_test.shape),(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77       128\n",
      "           1       0.76      0.81      0.79       134\n",
      "           2       0.82      0.60      0.70        53\n",
      "           3       0.80      0.80      0.80        66\n",
      "\n",
      "    accuracy                           0.77       381\n",
      "   macro avg       0.79      0.75      0.76       381\n",
      "weighted avg       0.78      0.77      0.77       381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tnappoly/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = logreg.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "report = classification_report(y_test, preds)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_train = logreg.score(X_train, y_train)\n",
    "\n",
    "logreg_test = logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9480263157894737\n",
      "Testing Accuracy:  0.7742782152230971\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy:  {logreg_train}')\n",
    "print(f'Testing Accuracy:  {logreg_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.78      0.67       128\n",
      "           1       0.58      0.80      0.67       134\n",
      "           2       0.67      0.04      0.07        53\n",
      "           3       0.77      0.26      0.39        66\n",
      "\n",
      "    accuracy                           0.59       381\n",
      "   macro avg       0.65      0.47      0.45       381\n",
      "weighted avg       0.63      0.59      0.54       381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Fit the model on the training data\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = nb.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "report = classification_report(y_test, preds)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = nb.score(X_train, y_train)\n",
    "nb_test = nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9006578947368421\n",
      "Testing Accuracy:  0.5931758530183727\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy:  {nb_train}')\n",
    "print(f'Testing Accuracy:  {nb_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.71      0.52       128\n",
      "           1       0.50      0.38      0.43       134\n",
      "           2       0.20      0.06      0.09        53\n",
      "           3       0.40      0.26      0.31        66\n",
      "\n",
      "    accuracy                           0.43       381\n",
      "   macro avg       0.38      0.35      0.34       381\n",
      "weighted avg       0.41      0.43      0.39       381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Fit the model on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = knn.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "report = classification_report(y_test, preds)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train = knn.score(X_train, y_train)\n",
    "knn_test = knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.6118421052631579\n",
      "Testing Accuracy:  0.4251968503937008\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy:  {knn_train}')\n",
    "print(f'Testing Accuracy:  {knn_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.77      0.66       128\n",
      "           1       0.55      0.77      0.64       134\n",
      "           2       0.90      0.17      0.29        53\n",
      "           3       0.94      0.24      0.39        66\n",
      "\n",
      "    accuracy                           0.59       381\n",
      "   macro avg       0.74      0.49      0.49       381\n",
      "weighted avg       0.68      0.59      0.56       381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds = rf.predict(X_test)\n",
    "\n",
    "# Model evaluation\n",
    "report = classification_report(y_test, preds)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train = rf.score(X_train, y_train)\n",
    "rf_test = rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  0.5931758530183727\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Accuracy:  {rf_train}')\n",
    "print(f'Testing Accuracy:  {rf_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
